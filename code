import cv2 as cv
from ultralytics import YOLO
import imutils
from deep_sort_realtime.deepsort_tracker import DeepSort
import numpy as np


def processVideo():
    counter_cache = []
    detection_classes = []
    count = 0
    path = "ABA Therapy - Play.mp4"  # Update with your actual video path
    # Read video
    vs = cv.VideoCapture(path)
    # Load the model
    model = YOLO('yolov8n.pt')

    object_tracker = DeepSort(max_iou_distance=0.7,
                              max_age=5,
                              n_init=3,
                              nms_max_overlap=1.0,
                              max_cosine_distance=0.2,
                              nn_budget=None,
                              gating_only_position=False,
                              override_track_class=None,
                              embedder="mobilenet",
                              half=True,
                              bgr=True,
                              embedder_gpu=True,
                              embedder_model_name=None,
                              embedder_wts=None,
                              polygon=False,
                              today=None
                              )

    while True:
        (grabbed, frame) = vs.read()
        if not grabbed:
            break

        # Use the correct indices for children and adults
        results = model.predict(frame, stream=False, classes=[0, 1])
        print(results[0].names)
        detection_classes = results[0].names
        frame = draw_line(frame)
        for result in results:
            for data in result.boxes.data.tolist():
                x1, y1, x2, y2, conf, id = data
                class_name = detection_classes[int(id)]
                drawBox([x1, y1, x2, y2, conf, id], frame, class_name)

                print("Detected class: --", class_name)

            details = get_details(result, frame)
            tracks = object_tracker.update_tracks(details, frame=frame)

        for track in tracks:
            if not track.is_confirmed():
                continue  # Skip unconfirmed tracks

            track_id = track.track_id
            bbox = track.to_ltrb()

            cv.putText(frame, "ID: " + str(track_id), (int(bbox[0]), int(bbox[1])), cv.FONT_HERSHEY_SIMPLEX, 1,
                       (0, 255, 0), 2)
            cv.putText(frame, "Count: " + str(count), (100, 100), cv.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 2)

            if bbox[1] > int(frame.shape[0] / 2) and track_id not in counter_cache:
                counter_cache.append(track_id)
                count += 1
                cv.putText(frame, "Count: " + str(count), (100, 100), cv.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 2)

        # Show frames
        cv.imshow('image', frame)
        if cv.waitKey(1) & 0xFF == ord('q'):  # Exit if 'q' is pressed
            break

    # Release resources
    vs.release()
    cv.destroyAllWindows()


def drawBox(data, image, name):
    x1, y1, x2, y2, conf, id = data
    p1 = (int(x1), int(y1))
    p2 = (int(x2), int(y2))
    cv.rectangle(image, p1, p2, (0, 0, 255), 2)
    cv.putText(image, name, p1, cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

    return image


def get_details(result, image):
    classes = result.boxes.cls.numpy()
    conf = result.boxes.conf.numpy()
    xywh = result.boxes.xywh.numpy()

    detections = []
    for i, item in enumerate(xywh):
        sample = (item, conf[i], classes[i])
        detections.append(sample)

    return detections


def draw_line(image):
    depth = int(image.shape[0] / 2)
    p1 = (400, int(image.shape[0] / 2))
    p2 = (image.shape[1] - 200, int(image.shape[0] / 2))
    image = cv.line(image, p1, p2, (0, 255, 0), thickness=2)

    return image


processVideo()
